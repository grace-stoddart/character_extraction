{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This notebook scrapes character lists or novels in the Litbank corpus, from study websites CliffsNotes and SparkNotes.\n",
    "### Character lists are saved as dicts in data/Litabank/characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from misc import save_dict, open_dict\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths =  glob.glob(\"Litbank/texts/\"+\"*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characters_cliff_notes(html):\n",
    "    \"\"\"\n",
    "    Take html object from a URL as input, return lsit of character naems as output.\n",
    "    Character names may need cleaning afterwards.\n",
    "    \"\"\"\n",
    "    # html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    charSections = soup.find_all(\"p\", class_=\"litNoteText\")\n",
    "\n",
    "    charNames = []\n",
    "\n",
    "    for section in charSections:\n",
    "        if section.strong != None:\n",
    "\n",
    "            if section.strong.string != None:\n",
    "\n",
    "                charNames.append(section.strong.string)\n",
    "\n",
    "            else: \n",
    "                charNames.append(section.strong.a.string)\n",
    "\n",
    "\n",
    "        elif section.b != None:\n",
    "            charNames.append(section.b.string)\n",
    "\n",
    "        else:\n",
    "            charNames.append(None)\n",
    "\n",
    "    return charNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characters_spark_notes(html):\n",
    "    \"\"\"\n",
    "    Take html object from a URL as input, return lsit of character naems as output.\n",
    "    Character names may need cleaning afterwards.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    characters = None\n",
    "\n",
    "    # for tag in soup.find_all(\"meta\"):\n",
    "    #     if tag.get(\"name\", None) == \"keywords\":\n",
    "    #         characters = tag.get(\"content\", None)\n",
    "    #     else:\n",
    "    #         pass\n",
    "    \n",
    "    # if characters != []:\n",
    "    #     return characters.split(\", \")\n",
    "\n",
    "    # else:\n",
    "    charSections = soup.find_all(\"h3\", class_ = None)\n",
    "    charNames = []\n",
    "    for section in charSections:\n",
    "        charNames.append(section.get_text())\n",
    "\n",
    "    if charNames != []:\n",
    "        return charNames\n",
    "\n",
    "    else:\n",
    "        for tag in soup.find_all(\"meta\"):\n",
    "            if tag.get(\"name\", None) == \"keywords\":\n",
    "                characters = tag.get(\"content\", None)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        if characters != [] and characters != None:\n",
    "            return characters.split(\", \")\n",
    "        else:\n",
    "            print(\"couldn't find characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_and_title(filePath):\n",
    "    '''\n",
    "    Returns predicted Litbank story ID and story title, from the file path.\n",
    "    Story title has format like: the-wind-in-the-willows\n",
    "    '''\n",
    "    storyName = filePath.split(\"/\")[-1]\n",
    "    storyName = storyName.split(\".txt\")[0]\n",
    "\n",
    "    storyID = int(re.search(r'\\d+', storyName).group())\n",
    "\n",
    "    storyName = re.sub(r'[0-9]+', '', storyName)\n",
    "    storyName  = storyName.strip(\"_\")\n",
    "    storyName = storyName.replace('_','-')\n",
    "    storyName = storyName.replace(\"'\",'')\n",
    "\n",
    "    return storyID, storyName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_character_list_spark(charList):\n",
    "    '''\n",
    "    returns cleaned character list from SparkNotes\n",
    "    '''\n",
    "    cleanCharlist = charList[0]\n",
    "\n",
    "    if \"characters\" in cleanCharlist[0]:\n",
    "        del cleanCharlist[0]\n",
    "\n",
    "    for i, char in enumerate(cleanCharlist):\n",
    "        cleanCharlist[i] = char.strip()\n",
    "\n",
    "    return cleanCharlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_character_list_cliff(charList):\n",
    "    '''\n",
    "    returns cleaned character list from CliffsNotes\n",
    "    '''\n",
    "    cleanCharList = []\n",
    "\n",
    "    for list in charList:\n",
    "        for char in list:\n",
    "            cleanCharList.append(char)\n",
    "\n",
    "    for j in range(len(cleanCharList)-1, -1, -1):\n",
    "        if cleanCharList[j] == None:\n",
    "            del cleanCharList[j]\n",
    "\n",
    "    for j in range(len(cleanCharList)-1, -1, -1):\n",
    "        if \"Continued on next\".lower() in cleanCharList[j].lower():\n",
    "            del cleanCharList[j]\n",
    "\n",
    "    for i, char in enumerate(cleanCharList):\n",
    "        cleanCharList[i] = char.strip()\n",
    "\n",
    "        cleanCharList[i] = cleanCharList[i].replace(\"\\xa0\",\"\")\n",
    "\n",
    "    return cleanCharList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell to iterate through each text file name and: \n",
    "# see if character list is available on CliffsNotes\n",
    "# if so parse webpage\n",
    "# extract characters from the webpage\n",
    "# save to dictionary\n",
    "\n",
    "characterDictCliff = {}\n",
    "\n",
    "for i, filePath in enumerate(filePaths):\n",
    "\n",
    "    # get story name from the file path\n",
    "    storyID, storyName = get_id_and_title(filePath)\n",
    "\n",
    "    # get starting letter \n",
    "    startLetter = storyName.replace(\"the-\",\"\")\n",
    "    startLetter = startLetter[0]\n",
    "    \n",
    "    # construct cliff notes URL & get page\n",
    "    \n",
    "    pages = []\n",
    "\n",
    "    try:   \n",
    "        url = \"https://www.cliffsnotes.com/literature/\" + startLetter + \"/\" + storyName +\"/character-list\"\n",
    "        pages.append(urlopen(url))\n",
    "        successfulURL = url\n",
    "        \n",
    "        \n",
    "    except:\n",
    "\n",
    "        try:\n",
    "            url = \"https://www.cliffsnotes.com/literature/\" + startLetter + \"/\" + storyName.replace(\"-\",\"\") +\"/character-list\"\n",
    "            pages.append(urlopen(url))\n",
    "            successfulURL = url\n",
    "        \n",
    "        except:\n",
    "            try:\n",
    "                url = \"https://www.cliffsnotes.com/literature/\" + startLetter + \"/\" + (storyName.replace(\"the-\",\"\")) +\"/character-list\"\n",
    "                pages.append(urlopen(url))\n",
    "                successfulURL = url\n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    url = \"https://www.cliffsnotes.com/literature/\" + startLetter + \"/\" + (storyName.replace(\"the-\",\"\")).replace(\"-\",\"\") +\"/character-list\"\n",
    "                    pages.append(urlopen(url))\n",
    "                    successfulURL = url\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    # get multiple pages, if multiple pages exist:\n",
    "    multiPage = True\n",
    "    pageNum = 2\n",
    "    while multiPage:\n",
    "        urlTry = successfulURL + \"-\" + str(pageNum)\n",
    "\n",
    "        try:\n",
    "            pages.append(urlopen(urlTry))\n",
    "            pageNum += 1\n",
    "\n",
    "        except:\n",
    "            multiPage = False\n",
    "\n",
    "    \n",
    "    # extract character names from page and add to dict\n",
    "    characterDictCliff[storyID] = []\n",
    "\n",
    "    for page in pages:\n",
    "        characterDictCliff[storyID].append(get_characters_cliff_notes(page))\n",
    "\n",
    "    \n",
    "    print(i,'complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell to do the same as above but for SparkNotes\n",
    "\n",
    "characterDictSpark = {}\n",
    "\n",
    "for i, filePath in enumerate(filePaths):\n",
    "\n",
    "    # get story name from the file path\n",
    "    storyID, storyName = get_id_and_title(filePath)\n",
    "\n",
    "    # construct SparkNotes notes URL\n",
    "\n",
    "    try:   \n",
    "        url = \"https://www.sparknotes.com/lit/\" + storyName +\"/characters/\"\n",
    "        page = urlopen(url)\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            url = \"https://www.sparknotes.com/lit/\" + storyName.replace(\"-\",\"\") +\"/characters/\"\n",
    "            page = urlopen(url)\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                url = \"https://www.sparknotes.com/lit/\" + storyName.replace(\"the-\",\"\") +\"/characters/\"\n",
    "                page = urlopen(url)\n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    url = \"https://www.sparknotes.com/lit/\" + (storyName.replace(\"the-\",\"\")).replace(\"-\",\"\") +\"/characters/\"\n",
    "                    page = urlopen(url)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    characterDictSpark[storyID] = [get_characters_spark_notes(html)]\n",
    "\n",
    "    print(i,\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### create dictionary of litBank IDs and titles to help with analysis\n",
    "litBankDict = {}\n",
    "\n",
    "for path in filePaths:\n",
    "    storyID, storyName = get_id_and_title(path)\n",
    "    storyName = storyName.replace(\"-\",\" \")\n",
    "\n",
    "    litBankDict[storyID] = storyName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean character lists in each dictionary\n",
    "characterDictSparkClean= {}\n",
    "for key, value in characterDictSpark.items():\n",
    "    characterDictSparkClean[key] = clean_character_list_spark(value)\n",
    "\n",
    "characterDictCliffClean = {}\n",
    "for key, value in characterDictCliff.items():\n",
    "    characterDictCliffClean[key] = clean_character_list_cliff(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save litbank dict, characterCliffDict and characterSparkNotesDict\n",
    "save_dict(characterDictCliffClean, \"LitBank/characters/litbank_character_lists_from_cliff.p\")\n",
    "save_dict(characterDictSparkClean, \"LitBank/characters/litbank_character_lists_from_spark.p\")\n",
    "save_dict(litBankDict, \"LitBank/characters/litbank_ids_and_titles_dict.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('character-allennlp-4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f08a002cfb74b2506f54e27c15b4b151c42a9fcd7b5ae0eaf4159402e8079c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
