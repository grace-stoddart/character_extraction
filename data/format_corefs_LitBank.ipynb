{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from misc import open_dict, get_raw_text, save_dict\n",
    "from format_corefs_LitBank import get_coreference_chains_from_brat_annotation_file, litbank_to_allen_indices_map, cut_tokenized_document, add_allenNLP_indices_to_coref_dict, format_coref_dict, get_id_and_title, get_character_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get list of files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths =  glob.glob(\"LitBank/texts/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "characterDictCliffs = open_dict(\"LitBank/characters/litbank_character_lists_from_cliffs.p\")\n",
    "characterDictSpark = open_dict(\"LitBank/characters/litbank_character_lists_from_spark.p\")\n",
    "litBankDict = open_dict(\"LitBank/characters/litbank_ids_and_titles_dict.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_characters = list(characterDictSpark.keys()) + list(characterDictCliffs.keys())\n",
    "have_characters = set(have_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNamesToProcess = []\n",
    "\n",
    "for filePath in filePaths:\n",
    "    storyID, _ = get_id_and_title(filePath)\n",
    "\n",
    "    if storyID in have_characters:\n",
    "        filePath = filePath.split('/')[-1]\n",
    "        filePath = filePath.split('.')[0]\n",
    "\n",
    "        fileNamesToProcess.append(filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45_anne_of_green_gables started\n",
      "766_david_copperfield started\n",
      "158_emma started\n",
      "2084_the_way_of_all_flesh started\n",
      "1023_bleak_house started\n",
      "74_the_adventures_of_tom_sawyer started\n",
      "113_the_secret_garden started\n",
      "2775_the_good_soldier started\n",
      "768_wuthering_heights started\n",
      "550_silas_marner started\n",
      "145_middlemarch started\n",
      "120_treasure_island started\n",
      "215_the_call_of_the_wild started\n",
      "105_persuasion started\n",
      "1400_great_expectations started\n",
      "27_far_from_the_madding_crowd started\n",
      "155_the_moonstone started\n",
      "2891_howards_end started\n",
      "219_heart_of_darkness started\n",
      "514_little_women started\n",
      "217_sons_and_lovers started\n",
      "2489_moby_dick started\n",
      "174_the_picture_of_dorian_gray started\n",
      "1342_pride_and_prejudice started\n",
      "599_vanity_fair started\n",
      "11_alices_adventures_in_wonderland started\n",
      "541_the_age_of_innocence started\n",
      "209_the_turn_of_the_screw started\n",
      "24_o_pioneers started\n",
      "730_oliver_twist started\n",
      "345_dracula started\n",
      "77_the_house_of_the_seven_gables started\n",
      "33_the_scarlet_letter started\n",
      "32_herland started\n",
      "543_main_street started\n",
      "432_the_ambassadors started\n",
      "4300_ulysses started\n",
      "2814_dubliners started\n"
     ]
    }
   ],
   "source": [
    "for fileName in fileNamesToProcess:\n",
    "\n",
    "    print(fileName, 'started')\n",
    "    # open annotated brat file\n",
    "    with open('LitBank/corefs_gold_brat/' + fileName + '_brat.ann') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        brat = list(reader)\n",
    "\n",
    "    # get coref chain annotations and put into dict\n",
    "    annotations_by_label = get_coreference_chains_from_brat_annotation_file(brat)\n",
    "\n",
    "    # convert indices from litbank character indices to allenNLP token indices\n",
    "    tokensAllen = open_dict('LitBank/tokenized/' + fileName + '.p')\n",
    "    bratInput = get_raw_text('LitBank/corefs_gold_brat/' + fileName + '_brat.txt')\n",
    "    tokenDict, tokenNum = litbank_to_allen_indices_map(tokensAllen, bratInput)\n",
    "\n",
    "    # shorten annotated text file to match length annotated in LitBank\n",
    "    tokenizedCut = cut_tokenized_document(tokenNum, tokensAllen)\n",
    "    save_dict(tokenizedCut, 'LitBank/tokenized_shortened/' + fileName + '.p')\n",
    "\n",
    "    # add AllenNLP indices to annotations dict\n",
    "    annotations_by_label_allenIndices = add_allenNLP_indices_to_coref_dict(annotations_by_label, tokenDict)\n",
    "\n",
    "    # get into same format as other coref dicts\n",
    "    coref_dict_final = format_coref_dict(annotations_by_label, tokenizedCut)\n",
    "\n",
    "    # save coref dict\n",
    "    save_dict(coref_dict_final, 'LitBank/corefs_gold_new_format/' + fileName + '.p')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label coreference chain according to whether it's a character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "characterDictCliffs = open_dict(\"LitBank/characters/litbank_character_lists_from_cliffs.p\")\n",
    "characterDictSpark = open_dict(\"LitBank/characters/litbank_character_lists_from_spark.p\")\n",
    "litBankDict = open_dict(\"LitBank/characters/litbank_ids_and_titles_dict.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap sotyr titles to story filepaths in litBankDict\n",
    "filePaths =  glob.glob(\"LitBank/texts/\"+\"*.txt\")\n",
    "\n",
    "for filePath in filePaths:\n",
    "\n",
    "    storyID, _ = get_id_and_title(filePath)\n",
    "\n",
    "    for key in litBankDict.keys():\n",
    "        if key == storyID:\n",
    "\n",
    "            filePath = filePath.split('/')[-1]\n",
    "            filePath = filePath.split('.')[0]\n",
    "\n",
    "            litBankDict[key] = filePath\n",
    "\n",
    "\n",
    "save_dict(litBankDict, \"LitBank/characters/litbank_ids_and_titles_dict.p\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get dict of stories with filenames and characters\n",
    "characters_all = {}\n",
    "\n",
    "for key in litBankDict:\n",
    "    if key in list(characterDictSpark.keys()) and key in list(characterDictCliffs.keys()):\n",
    "\n",
    "        if key == 2814:\n",
    "            characters_all[key] = {\n",
    "                                'characterList':characterDictCliffs[key],\n",
    "                                'fileName':litBankDict[key]\n",
    "                                }\n",
    "\n",
    "        else:\n",
    "\n",
    "            values = [characterDictSpark[key], characterDictCliffs[key]]\n",
    "            sizes = [len(characterDictSpark[key]), len(characterDictSpark[key])]\n",
    "            \n",
    "            characters_all[key] = {\n",
    "                                    'characterList':values[sizes.index(max(sizes))],\n",
    "                                    'fileName':litBankDict[key]\n",
    "                                    }\n",
    "\n",
    "    elif key in list(characterDictSpark.keys()):\n",
    "        characters_all[key] = {\n",
    "                                'characterList':characterDictSpark[key],\n",
    "                                'fileName':litBankDict[key]\n",
    "                                }\n",
    "\n",
    "    elif key in list(characterDictCliffs.keys()):\n",
    "        characters_all[key] = {\n",
    "                                'characterList':characterDictCliffs[key],\n",
    "                                'fileName':litBankDict[key]\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### match coreference chains with characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corefsDir_gold = 'LitBank/corefs_gold_new_format/'\n",
    "charLabelsDir_gold = '../intermediate/LitBank/from_gold_corefs/character_labels_scraped/'\n",
    "\n",
    "corefsDir_allen = 'LitBank/corefs_allen/'\n",
    "charLabelsDir_allen = '../intermediate/LitBank/from_allenNLP_corefs/character_labels_scraped/'\n",
    "\n",
    "\n",
    "corefsDir = corefsDir_allen\n",
    "charLabelsDir = charLabelsDir_allen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story in characters_all.values():\n",
    "    characters = story['characterList']\n",
    "    fileName = story['fileName']\n",
    "    corefs = open_dict(corefsDir + fileName + '.p')\n",
    "\n",
    "    characterLabelsScraped = get_character_labels(corefs, characters)\n",
    "\n",
    "    np.save(charLabelsDir + fileName, characterLabelsScraped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('character-allennlp-4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f08a002cfb74b2506f54e27c15b4b151c42a9fcd7b5ae0eaf4159402e8079c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
